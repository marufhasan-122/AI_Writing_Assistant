{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MxZM1eClYTZb"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q torch sentencepiece\n",
        "!pip install -q transformers\n",
        "!pip install -q language-tool-python\n",
        "!pip install -q nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Ensure required NLTK data is present\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYybvF4ndfOg",
        "outputId": "90203bc2-837a-447f-bc9e-fcc35ad23ceb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "def paraphrase_t5(text, num_return_sequences=3, num_beams=5, max_length=256):\n",
        "    \"\"\"\n",
        "    T5-based paraphraser. Returns a list of paraphrases.\n",
        "    \"\"\"\n",
        "    input_text = \"paraphrase: \" + text + \" </s>\"\n",
        "    encoding = tokenizer.encode_plus(input_text, padding='longest', return_tensors=\"pt\")\n",
        "    input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2\n",
        "    )\n",
        "    paraphrases = [tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True) for output in outputs]\n",
        "    # Deduplicate while preserving order\n",
        "    seen = set()\n",
        "    result = []\n",
        "    for p in paraphrases:\n",
        "        if p not in seen:\n",
        "            seen.add(p)\n",
        "            result.append(p)\n",
        "    return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq32Hl8saN0A",
        "outputId": "f4645183-6589-4cd1-c9a3-2905bea48354"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-17-jdk-headless -qq > /dev/null\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBpirg2jbJYw",
        "outputId": "1cbdcc42-9df3-46b5-fa63-0a16fe8cba27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.16\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import language_tool_python\n",
        "\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "def grammar_correct(text):\n",
        "    matches = tool.check(text)\n",
        "    corrected = language_tool_python.utils.correct(text, matches)\n",
        "    issues = []\n",
        "    for m in matches:\n",
        "        issues.append({\n",
        "            \"message\": m.message,\n",
        "            \"replacements\": m.replacements,\n",
        "            \"offset\": m.offset,\n",
        "            \"error_length\": m.errorLength\n",
        "        })\n",
        "    return {\"corrected\": corrected, \"issues\": issues}\n"
      ],
      "metadata": {
        "id": "-ZalVyo9axjg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Writing Assistant\n",
        "\n",
        "This notebook demonstrates a simple AI-powered writing assistant that can:\n",
        "- Check grammar and spelling\n",
        "- Suggest better vocabulary\n",
        "- Provide paraphrases\n",
        "- Adjust tone (formal/informal)\n"
      ],
      "metadata": {
        "id": "0nFRcq2chRTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.corpus.reader.wordnet import NOUN, VERB, ADJ, ADV\n",
        "import language_tool_python\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "id": "nfZ8u9zihI4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "\n",
        "def grammar_correct(text):\n",
        "    matches = tool.check(text)\n",
        "    corrected = language_tool_python.utils.correct(text, matches)\n",
        "    issues = []\n",
        "    for m in matches:\n",
        "        issues.append({\n",
        "            \"message\": m.message,\n",
        "            \"replacements\": m.replacements,\n",
        "            \"offset\": m.offset,\n",
        "            \"error_length\": m.errorLength\n",
        "        })\n",
        "    return {\"corrected\": corrected, \"issues\": issues}\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"\n",
        "    Convert treebank POS tags to wordnet POS tags for better synonym lookup.\n",
        "    \"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def suggest_vocabulary(text, top_n=3):\n",
        "    \"\"\"\n",
        "    For each content word return up to top_n synonyms from WordNet.\n",
        "    Returns dict[word] = [syn1, syn2...]\n",
        "    \"\"\"\n",
        "    from nltk.corpus import wordnet as wn\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    suggestions = {}\n",
        "    for word, tag in pos_tags:\n",
        "        wn_pos = get_wordnet_pos(tag)\n",
        "        if wn_pos is None:\n",
        "            continue\n",
        "        synsets = wn.synsets(word, pos=wn_pos)\n",
        "        # collect lemmas\n",
        "        lemmas = []\n",
        "        for s in synsets:\n",
        "            for l in s.lemmas():\n",
        "                name = l.name().replace('_', ' ')\n",
        "                if name.lower() != word.lower() and name.isalpha():\n",
        "                    lemmas.append(name)\n",
        "        # keep frequency-ish uniqueness\n",
        "        unique = []\n",
        "        for lem in lemmas:\n",
        "            if lem not in unique:\n",
        "                unique.append(lem)\n",
        "            if len(unique) >= top_n:\n",
        "                break\n",
        "        if unique:\n",
        "            suggestions[word] = unique\n",
        "    return suggestions\n",
        "\n",
        "def paraphrase_t5(text, num_return_sequences=3, num_beams=5, max_length=256):\n",
        "    \"\"\"\n",
        "    T5-based paraphraser. Returns a list of paraphrases.\n",
        "    \"\"\"\n",
        "    input_text = \"paraphrase: \" + text + \" </s>\"\n",
        "    encoding = tokenizer.encode_plus(input_text, padding='longest', return_tensors=\"pt\")\n",
        "    input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2\n",
        "    )\n",
        "    paraphrases = [tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True) for output in outputs]\n",
        "    # Deduplicate while preserving order\n",
        "    seen = set()\n",
        "    result = []\n",
        "    for p in paraphrases:\n",
        "        if p not in seen:\n",
        "            seen.add(p)\n",
        "            result.append(p)\n",
        "    return result\n",
        "\n",
        "def decide_and_run_agent(text, request_options=None):\n",
        "\n",
        "    if request_options is None:\n",
        "        request_options = {}\n",
        "\n",
        "    result = {\"original\": text}\n",
        "\n",
        "    # 1) Always run grammar check by default\n",
        "    grammar_res = grammar_correct(text)\n",
        "    result[\"grammar\"] = grammar_res\n",
        "\n",
        "    # 2) Vocabulary suggestions (only if requested OR always - here we do always)\n",
        "    vocab_res = suggest_vocabulary(grammar_res[\"corrected\"], top_n=3)\n",
        "    result[\"vocabulary_suggestions\"] = vocab_res\n",
        "\n",
        "    # 3) Paraphrase / rewrite (only if requested)\n",
        "    if request_options.get(\"paraphrase\", False):\n",
        "        num = request_options.get(\"paraphrase_count\", 3)\n",
        "        paraphrases = paraphrase_t5(grammar_res[\"corrected\"], num_return_sequences=num)\n",
        "        result[\"paraphrases\"] = paraphrases\n",
        "    else:\n",
        "        result[\"paraphrases\"] = []\n",
        "\n",
        "    # 4) Tone adjustment - simple rule: we'll rephrase with simple prompts for T5 if tone requested\n",
        "    tone = request_options.get(\"tone\", None)\n",
        "    if tone is not None:\n",
        "        # We'll generate 2 variations asking for a more formal/informal paraphrase\n",
        "        prompt_text = \"\"\n",
        "        if tone.lower() == \"formal\":\n",
        "            prompt_text = \"paraphrase (formal): \" + grammar_res[\"corrected\"]\n",
        "        elif tone.lower() == \"informal\":\n",
        "            prompt_text = \"paraphrase (informal): \" + grammar_res[\"corrected\"]\n",
        "        else:\n",
        "            prompt_text = \"paraphrase: \" + grammar_res[\"corrected\"]\n",
        "        # simple call\n",
        "        try:\n",
        "            torch.cuda.empty_cache()\n",
        "            encoding = tokenizer.encode_plus(prompt_text + \" </s>\", return_tensors=\"pt\").to(device)\n",
        "            outputs = model.generate(\n",
        "                **encoding,\n",
        "                max_length=256,\n",
        "                num_beams=4,\n",
        "                num_return_sequences=2,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "            tone_variations = [tokenizer.decode(o, skip_special_tokens=True, clean_up_tokenization_spaces=True) for o in outputs]\n",
        "        except Exception as e:\n",
        "            tone_variations = []\n",
        "        result[\"tone_variations\"] = tone_variations\n",
        "    else:\n",
        "        result[\"tone_variations\"] = []\n",
        "\n",
        "    return result\n",
        "\n",
        "# Simple interactive loop for testing in Colab (run this cell; stop when done)\n",
        "print(\"=== Simple AI Writing Assistant ===\")\n",
        "print(\"Type your English sentence/paragraph. Type 'exit' to quit.\")\n",
        "\n",
        "while True:\n",
        "    text = input(\"\\nYour text > \").strip()\n",
        "    if not text:\n",
        "        print(\"Please enter some text.\")\n",
        "        continue\n",
        "    if text.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Ask what extra options user wants\n",
        "    paraphrase_ans = input(\"Do you want paraphrases? (y/n) > \").strip().lower()\n",
        "    tone_ans = input(\"Do you want tone adjustment? (none/formal/informal) > \").strip().lower()\n",
        "    vocab_ans = input(\"Do you want vocabulary suggestions? (y/n) > \").strip().lower()\n",
        "\n",
        "    opts = {}\n",
        "    if paraphrase_ans == 'y':\n",
        "        try:\n",
        "            n = int(input(\"How many paraphrase variants (1-5)? > \").strip())\n",
        "            opts[\"paraphrase\"] = True\n",
        "            opts[\"paraphrase_count\"] = max(1, min(5, n))\n",
        "        except:\n",
        "            opts[\"paraphrase\"] = True\n",
        "            opts[\"paraphrase_count\"] = 2\n",
        "    if tone_ans in [\"formal\", \"informal\"]:\n",
        "        opts[\"tone\"] = tone_ans\n",
        "    if vocab_ans == 'y':\n",
        "        opts[\"vocab_suggest\"] = True\n",
        "\n",
        "    # Run agent\n",
        "    out = decide_and_run_agent(text, request_options=opts)\n",
        "\n",
        "    # Present results clearly\n",
        "    print(\"\\n--- RESULTS ---\")\n",
        "    print(\"\\nOriginal:\")\n",
        "    print(out[\"original\"])\n",
        "\n",
        "    print(\"\\nGrammar-corrected:\")\n",
        "    print(out[\"grammar\"][\"corrected\"])\n",
        "\n",
        "    if out[\"grammar\"][\"issues\"]:\n",
        "        print(\"\\nFound issues (few examples):\")\n",
        "        for iss in out[\"grammar\"][\"issues\"][:6]:\n",
        "            print(\"-\", iss[\"message\"], \"=> suggestions:\", iss[\"replacements\"])\n",
        "\n",
        "    if out[\"vocabulary_suggestions\"]:\n",
        "        print(\"\\nVocabulary suggestions (word : alternatives):\")\n",
        "        for w, alts in out[\"vocabulary_suggestions\"].items():\n",
        "            print(f\" {w} : {alts}\")\n",
        "\n",
        "    if out[\"paraphrases\"]:\n",
        "        print(\"\\nParaphrase suggestions:\")\n",
        "        for i, p in enumerate(out[\"paraphrases\"], 1):\n",
        "            print(f\" {i}. {p}\")\n",
        "\n",
        "    if out[\"tone_variations\"]:\n",
        "        print(\"\\nTone variations:\")\n",
        "        for i, t in enumerate(out[\"tone_variations\"], 1):\n",
        "            print(f\" {i}. {t}\")\n",
        "\n",
        "    print(\"\\n--- End of result ---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj6ZFcQfeddK",
        "outputId": "71fd132b-8e60-4e08-99cc-a56994683653"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "=== Simple AI Writing Assistant ===\n",
            "Type your English sentence/paragraph. Type 'exit' to quit.\n",
            "\n",
            "Your text > i dont know what to write. this is not good english and it seem wrong.\n",
            "Do you want paraphrases? (y/n) > y\n",
            "Do you want tone adjustment? (none/formal/informal) > y\n",
            "Do you want vocabulary suggestions? (y/n) > y\n",
            "How many paraphrase variants (1-5)? > 2\n",
            "\n",
            "--- RESULTS ---\n",
            "\n",
            "Original:\n",
            "i dont know what to write. this is not good english and it seem wrong.\n",
            "\n",
            "Grammar-corrected:\n",
            "I don't know what to write. This is not good English and it seems wrong.\n",
            "\n",
            "Found issues (few examples):\n",
            "- This sentence does not start with an uppercase letter. => suggestions: ['I']\n",
            "- Possible spelling mistake found. => suggestions: [\"don't\"]\n",
            "- This sentence does not start with an uppercase letter. => suggestions: ['This']\n",
            "- Possible spelling mistake found. => suggestions: ['English']\n",
            "- After ‘it’, use the third-person verb form “seems”. => suggestions: ['seems']\n",
            "\n",
            "Vocabulary suggestions (word : alternatives):\n",
            " do : ['make', 'perform', 'execute']\n",
            " know : ['cognize', 'cognise', 'experience']\n",
            " write : ['compose', 'pen', 'indite']\n",
            " is : ['be', 'exist', 'equal']\n",
            " not : ['non']\n",
            " good : ['full', 'estimable', 'honorable']\n",
            " English : ['side']\n",
            " seems : ['look', 'appear', 'seem']\n",
            " wrong : ['incorrect', 'improper', 'amiss']\n",
            "\n",
            "Paraphrase suggestions:\n",
            " 1. Paraphrase\n",
            " 2. Paraphrasephrase\n",
            "\n",
            "--- End of result ---\n",
            "\n",
            "\n",
            "Your text > exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Use\n",
        "\n",
        "1. Enter your English sentence or paragraph.\n",
        "2. Choose which features you want:\n",
        "   - Paraphrases\n",
        "   - Tone adjustment (formal/informal)\n",
        "   - Vocabulary suggestions\n",
        "3. Run the cell below to see the AI assistant's suggestions.\n"
      ],
      "metadata": {
        "id": "tjP-aKRuhjlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple interactive demo\n",
        "text = \"i dont know what to write. this is not good english and it seem wrong.\"\n",
        "options = {\"paraphrase\": True, \"paraphrase_count\": 2, \"tone\": \"formal\", \"vocab_suggest\": True}\n",
        "\n",
        "output = decide_and_run_agent(text, request_options=options)\n",
        "\n",
        "print(\"Original:\", output[\"original\"])\n",
        "print(\"Grammar-corrected:\", output[\"grammar\"][\"corrected\"])\n",
        "print(\"Vocabulary suggestions:\", output[\"vocabulary_suggestions\"])\n",
        "print(\"Paraphrases:\", output[\"paraphrases\"])\n",
        "print(\"Tone variations:\", output[\"tone_variations\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ukpRpunhlox",
        "outputId": "3ea38883-6a0e-4657-8bac-c37b5929497d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: i dont know what to write. this is not good english and it seem wrong.\n",
            "Grammar-corrected: I don't know what to write. This is not good English and it seems wrong.\n",
            "Vocabulary suggestions: {'do': ['make', 'perform', 'execute'], 'know': ['cognize', 'cognise', 'experience'], 'write': ['compose', 'pen', 'indite'], 'is': ['be', 'exist', 'equal'], 'not': ['non'], 'good': ['full', 'estimable', 'honorable'], 'English': ['side'], 'seems': ['look', 'appear', 'seem'], 'wrong': ['incorrect', 'improper', 'amiss']}\n",
            "Paraphrases: ['Paraphrase', 'Paraphrasephrase']\n",
            "Tone variations: [\"Paraphrase (formal): I don't know what to write.\", \"Paraphrase (formal): I don't know what to write, this is not good English and it seems wrong.\"]\n"
          ]
        }
      ]
    }
  ]
}